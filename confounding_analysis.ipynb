{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import r2_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = pd.read_csv('data/labels.csv')\n",
    "SMOTE = BorderlineSMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(csv_path: str, feat_to_predict: str):\n",
    "    # Load the entire csv file\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Join labels and data so that truth values are aligned with original data\n",
    "    lbls = LABELS[['id', feat_to_predict]]\n",
    "    temp = data.merge(lbls, on='id', how='left')\n",
    "    temp = temp.dropna()\n",
    "    # Extract only the ground truths\n",
    "    labels = pd.DataFrame(temp[feat_to_predict], columns=[feat_to_predict])\n",
    "    data = temp.drop(feat_to_predict, axis=1)\n",
    "    data = data.set_index('id')\n",
    "    data = pd.DataFrame(StandardScaler().fit_transform(data), columns=data.columns, index=data.index)\n",
    "\n",
    "    if feat_to_predict == 'Sex_Category':\n",
    "        labels['Sex_Category'] = labels['Sex_Category'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(X, y, model, scoring_f, smote):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y if smote else None)\n",
    "    if smote: X_train, y_train = SMOTE.fit_resample(X_train, y_train)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return scoring_f(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset: str, target: str, features: list[str]):\n",
    "    X, y = load_raw_data(f'data/{dataset}', target)\n",
    "    X = X[features]\n",
    "    regr = len(y[target].value_counts()) > 2\n",
    "\n",
    "    model = LinearRegression() if regr else SVC()\n",
    "    scoring_f = r2_score if regr else balanced_accuracy_score\n",
    "    metric = 'R2 Score' if regr else \"Accuracy\"\n",
    "\n",
    "    results = []\n",
    "    for _ in range(1000):\n",
    "        results.append(train_and_test(X, y[target], model, scoring_f, not regr))\n",
    "\n",
    "    avg, stdev, sk, krt = np.mean(results), np.std(results), stats.skew(results), stats.kurtosis(results)\n",
    "    print(f'  - {metric} Average:   {\"\" if avg<0 else \" \"}{avg:0.4f}')\n",
    "    print(f'  - {metric} StDev:     {\"\" if stdev<0 else \" \"}{stdev:0.4f}')\n",
    "    print(f'  - {metric} Skew:      {\"\" if sk<0 else \" \"}{sk:0.4f}')\n",
    "    print(f'  - {metric} Kurtosis:  {\"\" if krt<0 else \" \"}{krt:0.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOCA_impairment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "  - R2 Score Average:   -0.2687\n",
      "  - R2 Score StDev:      0.2610\n",
      "  - R2 Score Skew:      -2.8738\n",
      "  - R2 Score Kurtosis:   15.7814\n",
      "\n",
      "Gender\n",
      "  - Accuracy Average:    0.6430\n",
      "  - Accuracy StDev:      0.0754\n",
      "  - Accuracy Skew:      -0.0327\n",
      "  - Accuracy Kurtosis:  -0.0260\n",
      "\n",
      "Education\n",
      "  - R2 Score Average:   -0.2641\n",
      "  - R2 Score StDev:      0.2630\n",
      "  - R2 Score Skew:      -1.5857\n",
      "  - R2 Score Kurtosis:   3.4251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = 'no_audio_corrected.csv'\n",
    "feats = [\n",
    "    '# unique tokens (participant)', '# DATE (participant)', '# AUX (participant)', '# CCONJ (participant)',\n",
    "    'RatioVerb', '# VERB (participant)', 'proportion_below_threshold_0.5', 'VP_to_AUX_ADJP (participant)'\n",
    "]\n",
    "\n",
    "print('Age')\n",
    "evaluate(dataset, 'Age_at_testing', feats)\n",
    "\n",
    "print('Gender')\n",
    "evaluate(dataset, 'Sex_Category', feats)\n",
    "\n",
    "print('Education')\n",
    "evaluate(dataset, 'Educ', feats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABAB<sub>42</sub>/ABAB<sub>40</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "  - R2 Score Average:   -0.4386\n",
      "  - R2 Score StDev:      0.4782\n",
      "  - R2 Score Skew:      -1.8909\n",
      "  - R2 Score Kurtosis:   4.4367\n",
      "\n",
      "Gender\n",
      "  - Accuracy Average:    0.6371\n",
      "  - Accuracy StDev:      0.0777\n",
      "  - Accuracy Skew:      -0.0543\n",
      "  - Accuracy Kurtosis:  -0.0682\n",
      "\n",
      "Education\n",
      "  - R2 Score Average:   -0.3104\n",
      "  - R2 Score StDev:      0.3068\n",
      "  - R2 Score Skew:      -2.0742\n",
      "  - R2 Score Kurtosis:   6.6792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = 'no_audio_corrected.csv'\n",
    "feats = [\n",
    "    'RatioVerb', 'RatioNoun', 'VP_to_AUX_VP (participant)', '# PROPN (participant)', 'MATTR (participant)',\n",
    "    '# NUM (participant)', '# TIME (participant)', '# unique tokens (participant)', 'VPTypeRate'\n",
    "]\n",
    "\n",
    "print('Age')\n",
    "evaluate(dataset, 'Age_at_testing', feats)\n",
    "\n",
    "print('Gender')\n",
    "evaluate(dataset, 'Sex_Category', feats)\n",
    "\n",
    "print('Education')\n",
    "evaluate(dataset, 'Educ', feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tTau/AB<sub>42</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "  - R2 Score Average:   -0.4250\n",
      "  - R2 Score StDev:      0.3498\n",
      "  - R2 Score Skew:      -1.9450\n",
      "  - R2 Score Kurtosis:   7.3815\n",
      "\n",
      "Gender\n",
      "  - Accuracy Average:    0.4978\n",
      "  - Accuracy StDev:      0.0749\n",
      "  - Accuracy Skew:      -0.1279\n",
      "  - Accuracy Kurtosis:  -0.1198\n",
      "\n",
      "Education\n",
      "  - R2 Score Average:   -0.3439\n",
      "  - R2 Score StDev:      0.7508\n",
      "  - R2 Score Skew:      -7.0141\n",
      "  - R2 Score Kurtosis:   71.3173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = 'full_corrected.csv'\n",
    "feats = [\n",
    "    'PU', 'UP', '1F0std', 'avgdurvoiced', 'stddurpause', 'maxdurpause', 'PVU', 'VP'\n",
    "]\n",
    "\n",
    "print('Age')\n",
    "evaluate(dataset, 'Age_at_testing', feats)\n",
    "\n",
    "print('Gender')\n",
    "evaluate(dataset, 'Sex_Category', feats)\n",
    "\n",
    "print('Education')\n",
    "evaluate(dataset, 'Educ', feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pTau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "  - R2 Score Average:   -0.4530\n",
      "  - R2 Score StDev:      0.3845\n",
      "  - R2 Score Skew:      -3.1088\n",
      "  - R2 Score Kurtosis:   23.1970\n",
      "\n",
      "Gender\n",
      "  - Accuracy Average:    0.7202\n",
      "  - Accuracy StDev:      0.0724\n",
      "  - Accuracy Skew:      -0.2556\n",
      "  - Accuracy Kurtosis:  -0.1049\n",
      "\n",
      "Education\n",
      "  - R2 Score Average:   -0.2808\n",
      "  - R2 Score StDev:      0.2344\n",
      "  - R2 Score Skew:      -1.7216\n",
      "  - R2 Score Kurtosis:   4.8241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = 'full_corrected.csv'\n",
    "feats = [\n",
    "    'PU', 'UP', 'Vrate', 'VP_to_AUX_VP (participant)', 'VP_to_AUX (participant)', 'skwdurvoiced', 'kurtosisdurvoiced', 'RatioVerb'\n",
    "]\n",
    "\n",
    "print('Age')\n",
    "evaluate(dataset, 'Age_at_testing', feats)\n",
    "\n",
    "print('Gender')\n",
    "evaluate(dataset, 'Sex_Category', feats)\n",
    "\n",
    "print('Education')\n",
    "evaluate(dataset, 'Educ', feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
